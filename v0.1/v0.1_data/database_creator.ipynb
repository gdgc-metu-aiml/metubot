{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8224/2701862708.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader,PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = model_path,      \n",
    "    model_kwargs = model_kwargs,  \n",
    "    encode_kwargs = encode_kwargs \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create an empty FAISS index\n",
    "dimension = 384  # Match the dimension of your embedding model\n",
    "empty_index = faiss.IndexFlatL2(dimension)\n",
    "docstore = InMemoryDocstore({})\n",
    "faiss_db = FAISS(embedding_function=embeddings, index=empty_index,index_to_docstore_id={},docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=750,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get file path's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './files/'\n",
    "files = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./files/ODTUAkademikDurustluk-Kilavuzu-7.3.2016.son_.pdf\n",
      "./files/7417_sayili_kanun_ile_2547_sayili_kanuna_eklenen_gecici_madde_83_uygulama_ilkeleri.pdf\n",
      "./files/1.5.2547.pdf\n",
      "empty pdf: ./files/7143_Sayili_Kanunun_Uygulama_ilkeleri.pdf\n",
      "./files/suny_burs_yonergesi.pdf\n",
      "./files/metu_programs_tr.csv\n",
      "./files/reg_final.csv\n",
      "./files/metudata.csv\n",
      "./files/metu1_tr.csv\n",
      "./files/metu_registration_tr.csv\n",
      "./files/2016-2024-odtu-kazanimlari.pdf\n",
      "./files/ODTU_20Sinav_20Kurallari-Kilavuz-7.4.2016.son_.pdf\n",
      "./files/metu_int_registration_tr.csv\n",
      "csv count: 6 | pdf count: 6\n"
     ]
    }
   ],
   "source": [
    "csv_count = 0\n",
    "pdf_count = 0\n",
    "csv_args={'delimiter': ','}\n",
    "for file in files:\n",
    "\n",
    "    ##### CSV Loader\n",
    "    if file.endswith('.csv'):\n",
    "        document = CSVLoader(file_path=folder + file,csv_args=csv_args,encoding='utf-8').load()\n",
    "        splitted_text = text_splitter.split_documents(document)\n",
    "        faiss_db.add_documents(splitted_text)\n",
    "        csv_count += 1\n",
    "        print(folder + file)\n",
    "    \n",
    "\n",
    "    ######PDF Loader\n",
    "    elif file.endswith('.pdf'):\n",
    "        document = PyPDFLoader(folder + file).load()\n",
    "        try:\n",
    "            splitted_text = text_splitter.split_documents(document)\n",
    "            faiss_db.add_documents(splitted_text)\n",
    "            pdf_count += 1\n",
    "            print(folder + file)\n",
    "        except:\n",
    "            print(f\"empty pdf: {folder + file}\")\n",
    "\n",
    "print(f\"csv count: {csv_count} | pdf count: {pdf_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_db.save_local(\"faiss_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metubot",
   "language": "python",
   "name": "metubot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
